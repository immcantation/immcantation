---
title: "Single Cell V(D)J Analysis Tutorial"
output: html_document
---

# Single Cell V(D)J Analysis Tutorial

## Overview

This tutorial is a basic walk-through for defining B cell clonal families and building B cell lineage trees using [10x Genomics](https://www.10xgenomics.com/products/single-cell-immune-profiling) BCR sequencing data. 

Knowledge of basic command line usage is assumed. Please check out the individual documentation sites for the functions detailed in this tutorial before using them on your own data. 

* For simplicity, this tutorial will use the [Immcantation Lab Docker image](https://hub.docker.com/repository/docker/immcantation/lab) which contains R Markdown notebooks and all necessary software to run this code.
  * You can download the current Docker image with `docker pull immcantation/lab:devel`
  * For some operating systems, it may be necessary to use super-user privileges (sudo), and/or to have [Docker Desktop](https://hub.docker.com/editions/community/docker-ce-desktop-windows) running before entering the previous command.
* It is also possible to install the packages being used separately (see [pRESTO](https://presto.readthedocs.io/en/stable/install.html#installation), [Change-O](https://changeo.readthedocs.io/en/stable/install.html#installation), and [Alakazam](https://alakazam.readthedocs.io/en/stable/install/)).

You may also reference [this page](https://immcantation.readthedocs.io/en/stable/docker/pipelines.html) for an example pipeline script to process 10x data with Immcantation's [changeo-10x](https://bitbucket.org/kleinstein/immcantation/src/master/pipelines/changeo-10x.sh) example script.

## Resources

* You can email [immcantation\@googlegroups.com](mailto:immcantation@googlegroups.com) with any questions or issues.
* Documentation: <http://immcantation.org>
* Source code and bug reports: <https://bitbucket.org/kleinstein/immcantation>
* Docker image for this tutorial: https://hub.docker.com/r/immcantation/lab

## Outline of tutorial 

* Assigning V, D, and J genes using IgBLAST
* Filtering records
* Integrating BCR and gene expression data
* Finding thresholds for cloning (automatically or manually)
* Performing clustering to define clonal groups
* Creating germlines
* Calculating SHM frequency in the heavy chain V genes
* Building and visualizing trees
* Analyzing B cell migration, differentiation, and evolution over time

## Getting started

10x BCR (B cell receptor) data and 10x GEX (gene expression) data can borrow information from each other for an improved analysis. This tutorial demonstrates a few approaches to integrating these data types along with examples on how the new information can be used.

The example dataset used in this tutorial is from the following paper:

Turner JS, Zhou JQ, Han J, Schmitz AJ, Rizk AA, Alsoussi WB, Lei T, Amor M, McIntire KM, Meade P, Strohmeier S, Brent RI, Richey ST, Haile A, Yang YR, Klebert MK, Suessen T, Teefey S, Presti RM, Krammer F, Kleinstein SH, Ward AB, Ellebedy AH. Human germinal centres engage memory and naive B cells after influenza vaccination. Nature. 2020 Oct;586(7827):127-132. doi: 10.1038/s41586-020-2711-0. Epub 2020 Aug 31. PMID: 32866963; PMCID: PMC7566073.

These two files are subsamples of the original 10x scRNA-seq and BCR sequencing data from Turner et al. (2020) *Human germinal centres engage memory and naive B cells after influenza vaccination* Nature. 586, 127--132 [link](https://www.nature.com/articles/s41586-020-2711-0) The study consists of blood and lymph node samples taken from a single patient at multiple time points following influenza vaccination.

We extracted a subset (~3000 cells) of single cell GEX/BCR data of ultrasound-guided fine needle aspiration (FNA) samples of lymph nodes for subject P05. The example dataset (BCR.data.rds and GEX.data.rds) can be downloaded in a zip file from here.

<!-- #TODO: update link to data and description according to current location -->
The example data is already in the container (`/home/magus/data/10x_data_2subj/`). If you want to, you can download it from [example data](http://clip.med.yale.edu/immcantation/examples/10x_data_2subj.zip) and unzip it.

* You will find two files called **filtered_contig.fasta** and **filtered_contig_annotations.csv** in the unzipped directory (*10x_data_2subj* unless you rename it). They are the direct Cell Ranger output files for donor 1. We are going to use the Ig V(D)J sequences from donor 1 to show how to process V(D)J data using Immcantation.
* You will also find a file called **sc5p_v2_hs_B_1k_multi_5gex_b_Multiplex_vdj_b_all_contig_igblast_db-pass.tsv**. This file contains processed Ig V(D)J sequences for donor 2, with assigned V, D, and J genes using AssignGenes.py and MakeDb.py. In the section of "Find the distance threshold for cloning automatically", those Ig V(D)J sequences together with the sequences from donor 1, were used to calculate the nearest neighbor distances across subjects.
* `../data/bcr_phylo_tutorial/BCR.data.tsv`: B-Cell Receptor Data. Adaptive Immune Receptor Repertoire (AIRR) tsv BCRs already aligned to IMGT V, D, and J genes. This process is not covered in this tutorial. To learn more visit <https://immcantation.readthedocs.io/en/stable/tutorials/tutorials.html>
* `../data/bcr_phylo_tutorial/GEX.data.rds`: Gene Expression Data. This file contains a Seurat object with RNA-seq data already processed and annotated. Processing and annotation are not covered in this tutorial. You can learn more on these topics in Seurat's documentation and tutorials: <https://satijalab.org/seurat/articles/pbmc3k_tutorial.html>


The R Markdown notebook with the code is also available in the container (`/home/magus/notebooks/10x_tutorial.Rmd`). 

```{bash, eval=FALSE}
cd /home/magus/notebooks/
ls ../data/10x_data_2subj
```

Use the command `versions report` to list the versions of the of the Immcantation tools installed in  the container:

```{bash, eval=FALSE}
docker run -it -v $PWD:/data:z immcantation/suite:devel bash
versions report
```

## Assign V, D, and J genes using IgBLAST

To process 10x V(D)J data, a combination of `AssignGenes.py` and `MakeDb.py` can be used to generate a TSV file compliant with the [AIRR Community Rearrangement schema](https://immcantation.readthedocs.io/en/stable/datastandards.html) that incorporates annotation information provided by the Cell Ranger pipeline. The files of **filtered_contig.fasta** and **filtered_contig_annotations.csv**, generated by `cellranger vdj`, can be found in the *outs* directory.

Generate AIRR Rearrangement data from the 10x V(D)J FASTA files using the steps below (the `\` just indicates a new line for visual clarity):

```{bash, eval=FALSE}
# TODO I made all the base statements eval=FALSE so it doesn't actually run, but displays. 
# if this is incorrect please let me know. 
# assign V, D, and J genes using IgBLAST
#AssignGenes.py igblast -s ../data/10x_data_2subj/filtered_contig.fasta -b /usr/local/share/igblast \
#   --organism human --loci ig --format blast --outdir results
# TODO: update path to final path in container
AssignGenes.py igblast -s /data/assets/BCR_data_sequences.fasta -b /usr/local/share/igblast \ 
   --organism human --loci ig --format blast --outdir results
```

```{bash, eval=FALSE}
# convert IgBLAST output to AIRR format
# TODO: update path to final path in container
MakeDb.py igblast -i results/BCR_data_sequences_igblast.fmt7 -s /data/assets/BCR_data_sequences.fasta \
   -r /usr/local/share/germlines/imgt/human/vdj/imgt_human_*.fasta \
   --10x /data/assets/filtered_contig_annotations.csv --extended
```

```{bash, eval=FALSE}
ls results
```

After running these commands, you should now have **BCR_data_sequences_igblast_db-pass.tsv** and **BCR_data_sequences_igblast.fmt7** in your `results` directory. 

* For a full listing of what the flags mean, see the commandline usage for [AssignGenes.py igblast](https://changeo.readthedocs.io/en/stable/tools/AssignGenes.html#assigngenes-py-igblast) and [MakeDb.py igblast](https://changeo.readthedocs.io/en/stable/tools/MakeDb.html#makedb-py-igblast). You can also read our ["Using IgBLAST"](https://changeo.readthedocs.io/en/stable/examples/igblast.html) which contains both commands.
* The `--10x filtered_contig_annotations.csv` specifies the path of the contig annotations file generated by `cellranger vdj`, which can be found in the *outs* directory.

Please note that:

* **all_contig.fasta** can be exchanged for **filtered_contig.fasta**, and **all_contig_annotations.csv** can be exchanged for **filtered_contig_annotations.csv**.
* The resulting tab-delimited table overwrites the V, D and J gene assignments generated by Cell Ranger and uses those generated by [IgBLAST](https://ncbi.github.io/igblast/) or [IMGT/HighV-QUEST](https://www.imgt.org/IMGTindex/IMGTHighV-QUEST.php) instead.
* To process mouse data and/or TCR data, alter the `--organism` and `--loci` arguments to `AssignGenes.py` accordingly (e.g., `--organism mouse`, `--loci tcr`) and use the appropriate V(D)J IMGT reference database (e.g., **IMGT_Mouse_TR*.fasta**)

## Load libraries

Note that you might need to install several Bioconductor packages.

```{r, warning=FALSE, message=FALSE}
# load libraries
suppressPackageStartupMessages(library(airr))
suppressPackageStartupMessages(library(alakazam))
suppressPackageStartupMessages(library(data.table))
suppressPackageStartupMessages(library(dowser))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(scoper))
suppressPackageStartupMessages(library(Seurat))
suppressPackageStartupMessages(library(shazam))

# Bioconductor
suppressPackageStartupMessages(library(ggtree))
```

## Filter records

### Merging different samples

In order to merge different samples together for an common analysis, a column needs to be added to the resulting table to identify the sample. Additionally, the sequence IDs, need to be made unique across samples, for example by appending the `sample` ID to them. This step has been performed and the resulting table can be found under `assets/BCR_data.tsv`.

```{r}
# read in the data
# update to pull from zenoto
bcr_data <- airr::read_rearrangement("assets/BCR_data.tsv")
```

### Removing non-productive sequences

You may wish to subset your data to only productive sequences:

```{r}
# read in the data
bcr_data <- bcr_data %>% dplyr::filter(productive)

cat(paste("There are", nrow(bcr_data), "rows in the data.\n"))
bcr_data %>% slice_sample(n = 5) # random examples
```

### Cells with multiple heavy chains

If your single cell data contains cells with multiple heavy chains, you need to handle it before calling clones (B cells that descend from a common naive B cell ancestor).

A simple solution is just to remove cells with multiple heavy chains from the single cell data:

```{r}
# remove cells with multiple heavy chain
multi_heavy <- table(dplyr::filter(bcr_data, locus == "IGH")$cell_id)
multi_heavy_cells <- names(multi_heavy)[multi_heavy > 1]

bcr_data <- dplyr::filter(bcr_data, !cell_id %in% multi_heavy_cells)
cat(paste("There are", nrow(bcr_data), "rows in the data after filtering out cells
          with multiple heavy chains.\n"))
```

### Remove cells without heavy chains

Since most of the following analyses are based on heavy chains, we remove cells with only light chains:

```{r}
# split cells by heavy and light chains
heavy_cells <- dplyr::filter(bcr_data, locus == "IGH")$cell_id
light_cells <- dplyr::filter(bcr_data, locus == "IGK" | locus == "IGL")$cell_id
no_heavy_cells <- light_cells[which(!light_cells %in% heavy_cells)]

bcr_data <- dplyr::filter(bcr_data, !cell_id %in% no_heavy_cells)
cat(paste("There are", nrow(bcr_data), "rows in the data after filtering out cells
          without heavy chains."))
```

## Load in and reformat the data

### GEX

```{r}
# update to pull from zenoto
gex_db <- readRDS(file.path("assets","GEX.data.rds"))
```

Inspect the data:

```{r}
# Object summary
# `print` can be used to obtain a general overview of the Seurat object (number of features, number of samples...).
head(gex_db)
```
```{r}
# `Idents` reports the cell ID and identities. The first annotation in this blood sample is a TCR.
# Cell type annotations
head(Idents(gex_db), 1)
```

### Inspect BCR (move this)

The default file format for all functions in Immcantation is the AIRR-C format as of release 4.0.0. The rearrangement data is stored in a table where each row is a sequence, and each column an annotation fields. To learn more about this format (including the valid field names and their expected values), visit the [AIRR-C Rearrangement Schema documentation](https://docs.airr-community.org/en/stable/datarep/rearrangements.html#fields).

```{r}
# object summary
head(bcr_data, 1)
```

It is possible to subset columns using regular `R` functions. The cell below shows how to subset some fields of interest for the first sequence in the table.

```{r}
# check out select columns
head(select(bcr_data, cell_id, v_call, j_call, sample, day), 1)
```

### Standardize cell IDs

Both of the example datasets have been processed separately, and use slightly different cell identifiers. To consolidate the data into one object, we need to standardize the cell identifiers. This step could be different, or not necessary at all, with other datasets.

```{r}
# Make cell IDs in BCR match those in Seurat Object
bcr_data$cell_id_unique <- paste0(bcr_data$sample, "_", bcr_data$cell_id)
bcr_data$cell_id_unique[1]
```

In addition, the cells in both datasets are not presented in the same order.

```{r}
# First id in the BCR data
bcr_data$cell_id_unique[1]
```

```{r}
# First id in the GEX data
Cells(gex_db)[1]
```

Having common cell identifiers, we will be able to bring BCR data into the Seurat object, or the gene expression and annotation data from the Seurat object into the BCR table, by matching `cell_id_unique`.

### Add GEX data to BCR object

#### Find the BCR cells in the GEX data

We repeat the `match` step, reversing the order. The vector `match.index` will now contain the positions of the BCR sequences in the GEX data.

```{r}
# Match indices to find the position of the BCR cells in the GEX data
# Different from finding the position of the GEX cells in the BCR data!
match.index <- match(bcr_data$cell_id_unique, Cells(gex_db))
```

Some BCRs don't have GEX information. This can happen, for example, if the cell for which BCR's are covered didn't pass the GEX processing and quality controls thresholds. The proportion of BCRs that do not have GEX information is:

```{r}
# What proportion of BCRs don’t have GEX information?
mean(is.na(match.index))
```

#### Transfer GEX annotations into the BCR data

The GEX cell annotations can be added as additional columns in the BCR table.

```{r}
# Add annotations to BCR data
cell.annotation <- as.character(Idents(gex_db))
bcr_data$gex_annotation <-
   unlist(lapply(match.index, function(x) {
      ifelse(is.na(x), NA, cell.annotation[x])
   }))
bcr_data$gex_annotation[1:5]
```

#### Remove cells without GEX data

```{r}
# Remove cells that didn’t match
bcr_data <- dplyr::filter(bcr_data, !is.na(gex_annotation))
```

## Cloning thresholds

**Goal:** Partition (cluster) sequences into clonally related lineages. Each lineage is a group of sequences that came from the same original naive cell.

Summary of the key steps:

- *Determine clonal clustering threshold:* sequences which are under this cut-off are clonally related.
- *Assign clonal groups:* add an annotation (`clone_id`) that can be used to identify a group of sequences that came from the same original naive cell.
- *Reconstruct germline sequences:* figure out the germline sequence of the common ancestor, before mutations are introduced during clonal expansion and SMH.

### Find the distance threshold for cloning manually

Hierarchical clustering is a widely used distance-based method for identify clonally related sequences. An implementation of the hierarchical clustering approach is provided via the `hierachicalClones` function in the [SCOPer](https://scoper.readthedocs.io/en/stable/) R package.

It is important to determine an appropriate threshold for trimming the hierarchical clustering into B cell clones before using this method. The ideal threshold for separating clonal groups is the value that separates the two modes of the nearest-neighbor distance distribution. The nearest-neighbor distance distribution can be generated by using the `distToNearest` function in the [shazam](https://shazam.readthedocs.io/en/stable/) R package.

We first split sequences into groups that share the same V and J gene assignments and that have the same junction (or equivalently CDR3) length. This is based on the assumption that members of a clone will share all of these properties. `distToNearest` performs this grouping step, then counts the number of mismatches in the junction region between all pairs of sequences in each group and returns the smallest non-zero value for each sequence. At the end of this step, a new column (`dist_nearest`) which contains the distances to the closest non-identical sequence in each group will be added to the BCR table. `findThreshold` uses the distribution of distances calculated in the previous step to determine an appropriate threshold for the dataset. This can be done using either a `density` or `mixture` based method. 

```{r}
dist_nearest <- distToNearest(dplyr::filter(bcr_data, locus == "IGH"))

# generate Hamming distance histogram
p1 <- ggplot(subset(dist_nearest, !is.na(dist_nearest)),
             aes(x = dist_nearest)) +
        geom_histogram(color = "white", binwidth = 0.02) +
        labs(x = "Hamming distance", y = "Count") +
        scale_x_continuous(breaks = seq(0, 1, 0.1)) +
        theme_bw() +
        theme(axis.title = element_text(size = 18))
plot(p1)
```

The resulting distribution is often bimodal, with the first mode representing sequences with clonal relatives in the dataset and the second mode representing singletons. We can inspect the plot of nearest-neighbor distance distribution generated above to manually select a threshold to separates the two modes of the nearest-neighbor distance distribution. 

For further details regarding inferring an appropriate threshold for the hierarchical clustering method, see the [Distance to Nearest Neighbor vignette](https://shazam.readthedocs.io/en/stable/vignettes/DistToNearest-Vignette/) in the shazam package.

### Find the distance threshold for cloning automatically

The figure shows the distance-to-nearest distribution for the repertoire. Typically, the distribution is bimodal. The first mode (on the left) represents
sequences that have at least one clonal relative in the dataset, while the second mode (on the right) is representative of the sequences that do not have
any clonal relatives in the data (sometimes called "singletons"). A reasonable threshold will separate these two modes of the distribution.

The threshold itself can be also found using the automatic `findThreshold` function. There are different ways to find the threshold and details can also be found in the [Distance to Nearest Neighbor vignette](https://shazam.readthedocs.io/en/stable/vignettes/DistToNearest-Vignette/) in the shazam package.

A robust way that we recommend is to use the nearest-neighbor distance of inter (between) clones as the background and select the threshold based on the specificity of this background distribution. 

```{r}
# find threshold for cloning automatically
threshold_output <- findThreshold(dist_nearest$dist_nearest,
                                  method = "gmm", model = "gamma-norm",
                                  cutoff = "user", spc = 0.995)
threshold <- threshold_output@threshold
threshold
```

```{r, warning=FALSE}
plot(threshold_output, binwidth = 0.02, silent = TRUE) +
  theme(axis.title = element_text(size = 18))
```

The nearest-neighbor distance distribution is not always bimodal. In this case, if the data have multiple subjects, we can calculate the nearest neighbor distances across subjects to initialize the Gaussian fit parameters of the nearest-neighbor distance of inter (between) clones distribution. 

The nearest neighbor distances across subjects can be calculated by specifying the parameter `cross` in the function `distToNearest`. And then when we call function `findThreshold`, Gaussian fit parameters can be initialized by setting parameter `cross = dist_crossSubj$cross_dist_nearest`.

In the above data there are two subjects. We will want to make make sure that the cross subject distToNearest values are valid. To calculate this do the following:



```{r}
# calculate cross subjects distribution of distance to nearest
dist_crossSubj <- distToNearest(dplyr::filter(bcr_data, locus == "IGH"),
                                nproc = 1, cross = "subject")

# find threshold for cloning automatically and initialize the Gaussian fit
# parameters of the nearest-neighbor

# distance of inter (between) clones using cross subjects distribution of distance to nearest
threshold_output <- findThreshold(dist_nearest$dist_nearest,
                                  method = "gmm", model = "gamma-norm",
                                  cross = dist_crossSubj$cross_dist_nearest,
                                  cutoff = "user", spc = 0.995)
threshold_withcross <- threshold_output@threshold
threshold_withcross
```

```{r}
# plot the threshold along the density plot
plot(threshold_output, binwidth = 0.02,
     cross = dist_crossSubj$cross_dist_nearest, silent = TRUE) +
  theme(axis.title = element_text(size = 18))
```

In the plot above, the top plot is the nearest-neighbor distance distribution within Subj1, and the bottom plot is the nearest neighbor distances across Subj1 and Subj2.

## Define clonal groups

Once a threshold is decided, we perform the clonal assignment. At the end of this step, the BCR table will have an additional column (`clone_id`) that provides an identifier for each sequence to indicate which clone it belongs to (i.e., sequences that have the same identifier are clonally-related). *Note that these identifiers are only unique to the dataset used to carry out the clonal assignments.* 

Note: will print out "running in bulk mode" because the subsampled example data has only heavy chains. [Other options](https://scoper.readthedocs.io/en/stable/topics/hierarchicalClones/#single-cell-data) available if light chains are included.

After we decide the threshold for calling clones, the `hierachicalClones` function in SCOPer package can be used to call clones using single cell mode:

```{r, eval=FALSE}
# call clones using hierarchicalClones
results <- hierarchicalClones(bcr_data, cell_id = "cell_id_unique",
                              threshold = threshold, only_heavy = TRUE,
                              split_light = TRUE, summarize_clones = FALSE, fields = "subject")
```
```{r, echo=FALSE}
results <- bcr_data
```

`HierarchicalClones` clusters B receptor sequences based on junction region sequence similarity within partitions that share the same V gene, J gene, and junction length, thus allowing for ambiguous V or J gene annotations. By setting it up the `cell_id` parameter, `HierarchicalClones` will run in single-cell mode with paired-chain sequences. With `only_heavy = FALSE` and `split_light = TRUE`, grouping should be done by using IGH plus IGK/IGL sequences and inferred clones should be split by the light/short chain (IGK and IGL) following heavy/long chain clustering.

### Visualizing clone size distributions

After calling clones, a clonal abundance distribution can be displayed. To estimate the clonal abundance, we will select only the heavy chains:

```{r fig.width=8, fig.height=12}
# calculate and plot the rank-abundance curve
abund <- estimateAbundance(results %>% filter(locus %in% c("IGH")), group = "sample", nboot=100)

plot(abund) + facet_wrap("sample", ncol=3)
```

Most real datasets, will have most clones of size 1 (one sequence). In this tutorial, we processed data to remove most of singleton clone and we don't see
the much higher peak at 1 that we would normally expect. 

```{r fig.height=12, fig.width=8}
# get clone sizes using dplyr functions
clone_sizes <- countClones(results %>% filter(locus %in% c("IGH")), groups = "sample")

# Plot cells per clone
ggplot(clone_sizes, aes(x = seq_count)) +
   geom_bar() + 
   facet_wrap("sample", ncol=3) +
   labs( x= "Sequences per clone") +
   theme_bw()
```

## Create Germlines

The goal is to reconstruct the sequence of the unmutated ancestor of each clone. We use a reference database of known alleles ([IMGT](http://www.imgt.org)). Because it is very difficult to accurately infer the D region and the junction region for BCR sequences, we mask this region with `N`.

Note: If you opted for a native installation to run this tutorial, you can obtain reference germlines from IMGT with:

        git clone https://bitbucket.org/kleinstein/immcantation
        immcantation/scripts/fetch_imgtdb.sh

Before B cell lineage trees can be built, it is necessary to construct the unmutated germline sequence for each B cell clone. Typically the IGH D segment is masked because the junction region of heavy chains often cannot be reliably reconstructed. Note that occasionally errors are thrown for some clones - this is typical and usually results in those clones being excluded.

In the example below, we read in the IMGT germline references from our Docker container. If you're using a local installation, you can download the most up-to-date reference genome by cloning the Immcantation repository and running the script:

```{bash, eval = FALSE}
# will create directories where it is run
git clone https://bitbucket.org/kleinstein/immcantation.git
./immcantation/scripts/fetch_imgtdb.sh 
```

And passing `"human/vdj/"` to the `readIMGT` function.

```{r}
# read in IMGT data if downloaded on your own (above)
# and update `dir` to use the path to your `human/vdj` folder
# references = readIMGT(dir = "human/vdj/")


# This won't be able to be run 
# It has to be be display only due to the lack of viable reference locations
# this also means that the data will need to already have germlines created. 
# Read in IMGT files in Docker container
references <- readIMGT(dir = "/usr/local/share/germlines/imgt/human/vdj")

# Reconstruct germlines
results <- createGermlines(results, references)

results_heavy <- dplyr::filter(results, locus == "IGH")
```

## Calculate SHM frequency in the V gene

Basic mutational load calculations can be performed by the function `observedMutations` in the [SHazaM](https://shazam.readthedocs.io/en/stable/) R package:

```{r}
# This is typically only done on heavy chains, but can also be done on light chains 
results_heavy <- dplyr::filterfilter(results, locus == "IGH")

# calculate SHM frequency in the V gene
data_mut <- observedMutations(results_heavy,
                              sequenceColumn = "sequence_alignment",
                              germlineColumn = "germline_alignment_d_mask",
                              regionDefinition = IMGT_V,
                              frequency = TRUE,
                              combine = TRUE,
                              nproc = 1)
```

The plot below shows the distribution of median mutation frequency of clones:

```{r}
# calculate the median mutation frequency of a clone
mut_freq_clone <- data_mut %>%
                    group_by(clone_id) %>%
                    summarize(median_mut_freq = median(mu_freq))

ggplot(mut_freq_clone, aes(median_mut_freq)) +
  geom_histogram(, binwidth = 0.005) +
  theme_bw() + theme(axis.title = element_text(size = 18))
```

The plots below show the distribution of mutation frequency of cells by subject, isotype and cell type:

```{r}
# plotting mu_freq by subject
ggplot(data_mut, aes(y = mu_freq, x = subject, fill = subject)) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.3) +
  labs(x = "", y = "Mutation frequency", fill = "Subject") +
  theme(axis.text.x = element_blank())
```

```{r}
# plotting mu_freq by isotype
ggplot(data_mut, aes(y = mu_freq, x = c_gene, fill = c_gene)) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.3) +
  labs(x = "", y = "Mutation frequency", fill = "Isotype") +
  theme(axis.text.x = element_blank())
```

```{r}
# plotting mu_freq by cell type
ggplot(data_mut, aes(y = mu_freq, x = gex_annotation, fill = gex_annotation)) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.3) +
  labs(x = "", y = "Mutation frequency", fill = "Cell type") +
  theme(axis.text.x = element_blank())
```

## Building and visualizing trees

1.  Formatting clones
2.  Tree building
3.  Visualize trees
4.  Reconstruct intermediate sequences

### Formatting clones with dowser

In the rearrangement table, each row corresponds to a sequence, and each column is information about that sequence. We will create a new data structure, where each row is a clonal cluster, and each column is information about that clonal cluster. The function `formatClones` performs this processing and has options that are relevant to determine how the trees can be built and visualized. For example, `traits` determines the columns from the rearrangement data that will be included in the `clones` object, and will also be used to determine the uniqueness of the sequences, so they are not collapsed.

```{r}
# Make clone objects with aligned, processed sequences
# collapse identical sequences unless differ by trait
# add up duplicate_count column for collapsed sequences
# store day, isotype, gex_annotation
# discard clones with < 5 distinct sequences
clones <- formatClones(results,
                       traits = c("day", "gex_annotation"),
                       num_fields = c("duplicate_count"), minseq = 5, nproc = 1)
clones
```



```{r, echo=FALSE, eval=FALSE}
# this can be used once the new version of Dowser is released. 
# Additionally, if there is paired heavy and light chain data, you can format the clones such that the paired data is used in building trees. There is an additional step that occurs before the `formatClones` step in this situation. In order for the trees to best use the addition of light chain information, we will need to assign `clone_subgroups` using dowser's function `resolveLightChains`. This group cells within a clone based on the light chain V and J gene and assign a subgroup to each sequence. Then, in the `formatClones` step, speciy `chain="HL"`. 
comb <- resolveLightChains(results, nproc = 1)

clones <- formatClones(comb,
                       chain = "HL", traits = c("day", "gex_annotation"),
                       num_fields = c("duplicate_count"), minseq = 5, nproc = 1)
clones
```


### Tree building with dowser

Dowser offers multiple ways to build B cell phylogenetic trees. These differ by the method used to estimate tree topology and branch lengths (e.g. maximum parsimony and maximum likelihood) and implementation (IgPhyML, PHYLIP, RAxML, or R packages ape and phangorn). Each method has pros and cons.

#### Maximum parsimony

This is the oldest method and very popular. It tries to minimize the number of mutations from the germline to each of the tips. It can produce misleading results when parallel mutations are present.

```{r}
# Two options for maximum parsimony trees
# 1. phangorn
trees <- getTrees(clones)
head(trees)
```

```{r, eval=FALSE}
# 2. dnapars (PHYLIP)
trees <- getTrees(clones, build = "dnapars", exec = "/usr/local/bin/dnapars")
```

#### Standard maximum likelihood

These methods model each sequence separately. Use a markov model of the mutation process and try to find the tree, not the branch lengths, that maximizes the likelihood of seen data.

```{r}
# Two options for standard maximum likelihood trees
# 1. pml (phangorn)
trees <- getTrees(clones, build = "pml", sub_model = "GTR", nproc = 1)
head(trees)
```

```{r, eval=FALSE}
# 2. dnaml (PHYLIP)
trees <- getTrees(clones, build = "dnaml", exec = "/usr/local/bin/dnaml")
```

```{r, eval=FALSE, echo=FALSE}
# this is another thing for the dowser release, can get rid of the echo statement then 
# 3. RAxML (RAxML-ng)
trees <- getTrees(clones, build = "raxml", exec = "/user/local/raxml-ng/bin/raxml-ng")
```

#### B Cell specific maximum likelihood

Similar to the standard maximum likelihood, but incorporating SHM specific mutation biases into the tree building.

```{r, eval = FALSE}
# B cell specific maximum likelihood with IgPhyML
trees <- getTrees(clones, build = "igphyml", exec = "/usr/local/igphyml/src/igphyml", nproc=1)
```


```{r, echo=FALSE, eval=FALSE}
# more release realted content. Once it's release the echo=FALSE can be deleted
#### Partitioned maximum likelihood 
# 
# In addition to standard and b cell specific maximum likelihood, dowser offers partitioned maximum likelihood approaches for `RAxML` and `IgPhyML`. This approach should only be used when there is paired heavy and light chain data, not just heavy chain data because both methods will partition on the heavy chain and light chains separately. 
# RAxML
trees <- getTrees(clones, build = "raxml", exec = "/user/local/raxml-ng/bin/raxml-ng", partition = TRUE)
# IgPhML
trees <- getTrees(clones, build = "igphyml", exec = "/user/local/igphyml/src/igphyml", omega = "e,e", rates = "0,1")
```


### Plotting trees with dowser and ggtree

Regardless of how you build trees, they are visualized in the same manner with the `plotTrees` function. This will return a list of `ggplot` objects in the same order as the input object. Here, we color the tips by the `isotype` value because we specified that column in the `formatClones` step.

```{r}
# Plot all trees
plots_all <- plotTrees(trees, tips = "day", tipsize = 2) # c_call is the standard
```

```{r}
# Plot the largest tree
plots_all[[1]]
```

```{r, eval=FALSE}
# Save PDF of all trees
dir.create("results/dowser_tutorial/", recursive = TRUE)
treesToPDF(plots_all,
           file = file.path("results", "dowser_tutorial", "final_data_trees.pdf"),
           nrow = 2, ncol = 2)
```

### More elaborate tree plots

Plot trees so that tips are colored by cell type, scaled by sample day, and labelled by isotype.

```{r, warning=FALSE}

# Scale branches to mutations rather than mutations/site
trees <- scaleBranches(trees)

# Make fancy tree plot of second largest tree
plots_all <- plotTrees(trees, scale = 5)[[2]] +
                 geom_tippoint(aes(color = gex_annotation, size = day)) +
                 geom_tiplab(aes(label = day), offset = 0.002) 
print(plots_all)
```

### Reconstruct intermediate sequences

Sequences of intermediate nodes are automatically reconstructed during the tree build process. To retrieve them, first plot the node numbers for each node. The function `collapseNodes` can help clean up the tree plots. 

Get the predicted intermediate sequence at an internal node in the second largest tree. Dots represent IMGT gaps.

```{r, warning=FALSE}
# Collapse nodes with identical sequences
trees <- collapseNodes(trees)

# node_nums=TRUE labels each internal node
plots_all <- plotTrees(trees, node_nums = TRUE, labelsize = 6, scale = 5)[[2]] +
                 geom_tippoint(aes(color = gex_annotation, size = day)) +
                 geom_tiplab(aes(label = day), offset = 0.002)
print(plots_all)
```

```{r}
# Get sequence at node 26 for the second clone_id in trees
getNodeSeq(trees, clone = trees$clone_id[2], node = 26)
```

### Test for measurable evolution

Perform root-to-tip regression on each tree to detect if later-sampled timepoints are more diverged from the germline.

```{r}
# Correlation test
trees <- correlationTest(trees, time = "day", nproc = 1)

# Remove trees with one timepoint, order by p value
trees <- dplyr::filter(trees, !is.na(p))
trees <- trees[order(trees$p), ]

# Coloring tips by sample day
plots_time <- plotTrees(trees)
plots_time <- lapply(plots_time, function(x) {
  x +
    geom_tippoint(aes(fill = day), shape = 21, size = 3) +
    scale_fill_distiller(palette = "RdYlBu")
})
```
```{r}
select(trees, clone_id, slope, correlation, p)
print(plots_time[[1]])
```
```{r, eval=FALSE}
# Save all trees to a pdf file
treesToPDF(plots_time, file = file.path("results", "dowser_tutorial",
                                        "time_data_trees.pdf"))
```

### Analyzing B cell migration, differentiation, and evolution over time

In addition to the functions for building and visualizing trees, Dowser also implements new techniques for analyzing B cell migration and differentiation, as well as for detecting new B cell evolution over time. These are more advanced topics detailed on the [Dowser site](https://dowser.readthedocs.io).

If you have data from different **tissues, B cell subtypes, and/or isotypes** and want to use lineage trees to study the pattern of those traits along lineage trees, check out the [discrete trait vignette](https://dowser.readthedocs.io/en/latest/vignettes/Discrete-Trait-Vignette/).

If you have data from **multiple timepoints** from the same subject and want to determine if B cell lineages are evolving over the sampled interval, check out the [measurable evolution vignette](https://dowser.readthedocs.io/en/latest/vignettes/Measurable-Evolution/).

For more advanced tree **visualization**, check out the [plotting trees vignette](https://dowser.readthedocs.io/en/latest/vignettes/Plotting-Trees-Vignette/).
